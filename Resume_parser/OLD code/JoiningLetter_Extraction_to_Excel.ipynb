{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JoiningLetter_Extraction_to_Excel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2ieFLKkdBb+zJyZPZKgAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejal-7/Pdfminer/blob/master/JoiningLetter_Extraction_to_Excel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_QnlGrTjE92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68117ff5-7f1f-4de4-e63b-d88b051badc9"
      },
      "source": [
        "# spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# nltk\n",
        "!python -m nltk.downloader words\n",
        "!python -m nltk.downloader stopwords\n",
        "!pip install pyresparser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting pyresparser\n",
            "  Downloading pyresparser-1.0.6-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 16.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.5)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.62.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (21.2.0)\n",
            "Collecting nltk>=3.4.3\n",
            "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.0.5)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.2.4)\n",
            "Collecting docx2txt>=0.7\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting pdfminer.six>=20181108\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.4)\n",
            "Requirement already satisfied: pyrsistent>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.18.0)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.15.0)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.4.1)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.8.2)\n",
            "Collecting pycryptodome>=3.8.2\n",
            "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.1.5)\n",
            "Collecting pytz>=2019.1\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.4.0)\n",
            "Collecting urllib3>=1.25.3\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.23.0)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (7.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.10)\n",
            "Collecting jsonschema>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.6.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (57.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (1.0.1)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.5)\n",
            "Collecting urllib3>=1.25.3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->pyresparser) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->pyresparser) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six>=20181108->pyresparser) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six>=20181108->pyresparser) (2.20)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=5ce269a3a579384c64cf38ebdeffaf4bd42f7b4e7a734e2e6ffd5ac6741d4ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: urllib3, pytz, cryptography, pycryptodome, pdfminer.six, nltk, jsonschema, docx2txt, pyresparser\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed cryptography-3.4.8 docx2txt-0.8 jsonschema-3.2.0 nltk-3.6.2 pdfminer.six-20201018 pycryptodome-3.10.1 pyresparser-1.0.6 pytz-2021.1 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pkczjkuj-bm",
        "outputId": "b60b2654-9cc9-4b51-e6e6-a87925908bbc"
      },
      "source": [
        "!pip install PyPDF2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 39.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=0efdecadf45531d44b1ce322f07a4fad91f2cf4e4a371f03681fcceda06ef418\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5V2x3ROGLBK"
      },
      "source": [
        "Extract PDF to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMU37YMtkJOg"
      },
      "source": [
        "import PyPDF2\n",
        "\n",
        "# Extracting text from PDF\n",
        "\n",
        "def extractPDF (filePath):\n",
        "  pdfFileObj = open(filePath, 'rb')\n",
        "  content = \"\"\n",
        "  pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
        "  numberOfPages = pdfReader.numPages\n",
        "  for pageNum in range(0,1):\n",
        "    page = pdfReader.getPage(pageNum)\n",
        "    content += page.extractText()\n",
        "  contents = ''.join(content.split('\\n'))\n",
        "  return contents"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceCx87BlHFRB"
      },
      "source": [
        "Supporting Functions to extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG1oqOmskb0b"
      },
      "source": [
        "def replace_canadian_period(mail):\n",
        "    mail = mail.replace(u\"\\u1427\", \".\")\n",
        "    return mail\n",
        "def replace_fancy_hyphens(mail):\n",
        "    hlist = [u\"\\u002d\", u\"\\u058a\", u\"\\u058b\", u\"\\u2010\",   u\"\\u2011\", u\"\\u2012\", u\"\\u2013\", u\"\\u2014\", u\"\\u2015\", u\"\\u2e3a\", u\"\\u2e3b\", u\"\\ufe58\", u\"\\ufe63\", u\"\\uff0d\"]\n",
        "    for h in hlist:\n",
        "        mail = mail.replace(h, \"-\")\n",
        "    return mail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kGFYc9hlB3b"
      },
      "source": [
        "def lexical_processor(mail):\n",
        "    mail = replace_canadian_period(mail)\n",
        "    mail = replace_fancy_hyphens(mail)\n",
        "    return mail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKGeNhOslFlm"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en\") #we load the English models once, use it many times. Don't include this line into any methods, it'll dramatically reduce the efficiency\n",
        "def email_preprocessor(mail):\n",
        "    entities = {}\n",
        "    mail = lexical_processor(contents)     #mail is unicode\n",
        "    #mail = cut_greetings(email)        #mail is unicode\n",
        "    doc = nlp(mail)                    # doc is of spacy.doc type\n",
        "    entities['emails'] = extract_emails(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NeXfs63lLyZ"
      },
      "source": [
        "def extract_emails(doc):\n",
        "    resultlis = []\n",
        "    for token in doc:\n",
        "        if token.like_email:\n",
        "            resultlis.append((token.text))\n",
        "    return resultlis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH0XoJqCrfCX"
      },
      "source": [
        "def findDesignation (persons):\n",
        "  designations = [\"Software Engineer Intern\", \"Graduate Engineer Trainee\", \"Software Engineer\", \"Application Developer\", \"Project Intern\"]\n",
        "  for person in persons:\n",
        "    if person in designations:\n",
        "      return person"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YDpc-2AGWMf"
      },
      "source": [
        "Extract Basic Information from Extracted Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOQg_UUZlSFI"
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "def extractInformation (contents):\n",
        "  NER = spacy.load(\"en_core_web_sm\")\n",
        "  texts = NER(contents)\n",
        "\n",
        "  data = {}\n",
        "  data.setdefault('DESIGNATION', [])\n",
        "  data.setdefault('CITY', [])\n",
        "  persons = []\n",
        "  organizations = {\"\"}\n",
        "\n",
        "  for word in texts.ents:\n",
        "   if word.label_ == 'PERSON':\n",
        "     persons.append(word.text)\n",
        "   if word.label_ == 'ORG':\n",
        "     organizations.add(word.text)\n",
        "   if word.label_ == 'GPE':\n",
        "     data['CITY'].append(word.text)\n",
        "\n",
        "  desig = findDesignation(persons)\n",
        "  print(persons)\n",
        "  data['DESIGNATION'] = [desig]\n",
        "  persons.remove(desig)\n",
        "  data['PERSON'] = persons\n",
        "\n",
        "  data['ORG'] = list (organizations)\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(contents)\n",
        "\n",
        "  # Email matcher\n",
        "\n",
        "  emails = extract_emails(doc)\n",
        "  data['EMAIL'] = emails\n",
        "\n",
        "  #Phone Number Matcher \\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}\n",
        "\n",
        "  matcher = Matcher(nlp.vocab)\n",
        "  pattern = [{'LIKE_NUM': True}, {'LOWER': {'REGEX' : '\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}'}}]\n",
        "  matcher.add('PHONE', None, pattern)\n",
        "\n",
        "  matches = matcher(doc)\n",
        "  data['PHONE'] = [doc[start:end] for match_id, start, end in matches]\n",
        "\n",
        "  #Salary matcher\n",
        "  salary_start = re.compile(r'\\ INR | Rs.')\n",
        "  salary_init = salary_start.findall(contents)\n",
        "  #print(salary_init)\n",
        "  if salary_init[0] in [' Rs.']:\n",
        "    salary_pattern = re.compile(r' Rs.+/-')\n",
        "    salaries = salary_pattern.findall(contents)\n",
        "    data['SALARY'] = salaries\n",
        "  elif salary_init[0] in [' INR ']:\n",
        "    salary_pattern = re.compile(r'\\ INR [0-9,\\.]*')\n",
        "    salaries = salary_pattern.findall(contents)\n",
        "    data['SALARY'] = salaries\n",
        "\n",
        "  # date matcher\n",
        "\n",
        "  date_pattern = re.compile(r'((January|February|March|April|May|June|July|August|September|October|November|December)\\s([\\d]{4}|[\\d]{2}))')\n",
        "  dates = date_pattern.findall(contents)\n",
        "  data['JOINING DATE'] = dates\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_9SPjzclx-i",
        "outputId": "90c2d7bc-708f-4505-a76b-4e69910063d2"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CITY': ['Maharasitra', 'India'],\n",
              " 'DESIGNATION': ['Software Engineer Intern'],\n",
              " 'EMAIL': ['sejalace7@gmail.com', 'soubhik.das@manastik.com'],\n",
              " 'JOINING DATE': [('July 2021', 'July', '2021')],\n",
              " 'ORG': ['',\n",
              "  'Manastik',\n",
              "  'Non-DisclosureAgreement(\"Agreement\")containingManastik TechnologiesPvt',\n",
              "  'the Technical Architect',\n",
              "  'soubhik.das@manastik.com',\n",
              "  'CloudPlatforms',\n",
              "  'Company',\n",
              "  'INR',\n",
              "  'Android/Mobile Applications & Technologies'],\n",
              " 'PERSON': ['Welcometo Manastik'],\n",
              " 'PHONE': [+91 9284008178],\n",
              " 'SALARY': [' INR 2,000']}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2RL68GNFUpP"
      },
      "source": [
        "Write Extracted data to CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgrOz9QJmB2l"
      },
      "source": [
        "import csv\n",
        "\n",
        "def writeToCSV (data):\n",
        "  data_file = open('output.csv', 'w', newline='')\n",
        "  csv_writer = csv.writer(data_file)\n",
        "\n",
        "  # Writing data into csv file\n",
        "  header = data.keys()\n",
        "  csv_writer.writerow(header)\n",
        "  csv_writer.writerow(data.values())   # Sejal Resume      <-- data\n",
        "  print(\"Data inserted successfully...!  :)\")\n",
        "  data_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y47t2K_JGhOj"
      },
      "source": [
        "Main Function - to start execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUsf7o3dGmkV",
        "outputId": "ba29da84-4ce0-4400-9e26-edb1a6d8a1d1"
      },
      "source": [
        "# Extract data from resume\n",
        "extracted_text = extractPDF('/content/Manastik_Offer letter_Sejal.pdf')\n",
        "\n",
        "extracted_Data = extractInformation(extracted_text)\n",
        "# Write extracted data to CSV file\n",
        "writeToCSV(extracted_Data)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Welcometo Manastik', 'Software Engineer Intern']\n",
            "Data inserted successfully...!  :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOirQt3ZHM73"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}